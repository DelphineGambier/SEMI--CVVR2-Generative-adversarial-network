{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clean_to_dammaged_Final_Version.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S2LXjaPyoU94"},"source":["# GAN : Clean apples to dammaged apples"]},{"cell_type":"markdown","metadata":{"id":"urzsaWWaorFG"},"source":["## Required Installations :"]},{"cell_type":"code","metadata":{"id":"J0xRQMwFiZyl"},"source":["! pip install tensorflow \n","! pip install -q git+https://github.com/tensorflow/examples.git # install tensorflow_examples to use pix2pix model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xce7RJGdoLr5"},"source":["## Imports :"]},{"cell_type":"code","metadata":{"id":"lsxrwwunj5P8"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow_examples.models.pix2pix import pix2pix\n","\n","import os\n","import time\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","AUTOTUNE = tf.data.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NhW0tTThkMFB"},"source":["Creation of the training data"]},{"cell_type":"code","metadata":{"id":"eMuqnQf3kNBn"},"source":["image_size = (256, 256)\n","batch_size = 16 \n","\n","#Train \n","train_clean_apples = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/Clean_apple/\", # clean apple images directory \n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=123,\n","    color_mode='rgb',\n","    image_size=image_size,\n","    batch_size=batch_size,\n","    label_mode= None)\n","\n","train_dammaged_apples = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/Dammaged_apple\", # dammaged apple images directory \n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=123,\n","    color_mode='rgb',\n","    image_size=image_size,\n","    batch_size=batch_size,\n","    label_mode= None)\n","\n","#Test \n","test_clean_apples = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/Clean_apple/\", # clean apple images directory \n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=123,\n","    color_mode='rgb',\n","    image_size=image_size,\n","    batch_size=batch_size,\n","    label_mode= None)\n","\n","test_dammaged_apples = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/Dammaged_apple\", # dammaged apple images directory \n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=123,\n","    color_mode='rgb',\n","    image_size=image_size,\n","    batch_size=batch_size,\n","    label_mode= None)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WGC56mI9k8-Y"},"source":["## Images normalization :"]},{"cell_type":"code","metadata":{"id":"GgQ6r0pQk_tZ"},"source":["BUFFER_SIZE = 1000\n","BATCH_SIZE = 1\n","IMG_WIDTH = 256\n","IMG_HEIGHT = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKrGSXX-k-8_"},"source":["# normalize the images to [-1, 1]\n","def normalize(image,):\n","  image = tf.cast(image, tf.float32)\n","  image = (image / 127.5) - 1\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSf_M3__RIWz"},"source":["def preprocess_image(image):\n","  image = normalize(image)\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMUo1EHvyrSu"},"source":["train_clean_apples = train_clean_apples.map(\n","    preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n","\n","train_dammaged_apples = train_dammaged_apples.map(\n","    preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n","\n","test_clean_apples = test_clean_apples.map(\n","    preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n","\n","test_dammaged_apples = test_dammaged_apples.map(\n","    preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAxz9KI_zBcW"},"source":["## Visualization :"]},{"cell_type":"code","metadata":{"id":"6bqQkQqhzC9O"},"source":["sample_clean_apples = next(iter(train_clean_apples))\n","sample_dammaged_apples = next(iter(train_dammaged_apples))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xct8or2nzLfh"},"source":["plt.subplot(121)\n","plt.title('Clean Apple')\n","plt.imshow(sample_clean_apples[0] * 0.5 + 0.5)\n","\n","plt.subplot(122)\n","plt.title('Dammaged Apple')\n","plt.imshow(sample_dammaged_apples[0] * 0.5 + 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkgmeaKCrYfU"},"source":["## Model import :"]},{"cell_type":"code","metadata":{"id":"1PpFCPiJ1mFz"},"source":["OUTPUT_CHANNELS = 3\n","\n","generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","\n","discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K7zEr_o8sd2J"},"source":["Untrained model visualization"]},{"cell_type":"code","metadata":{"id":"eeskOIY2LHgy"},"source":["to_dammaged = generator_g(sample_clean_apples)\n","to_clean = generator_f(sample_dammaged_apples)\n","plt.figure(figsize=(8, 8))\n","contrast = 8\n","\n","imgs = [sample_clean_apples, to_dammaged, sample_dammaged_apples, to_clean]\n","title = ['Clean Apple', 'To Dammaged Apple', 'Dammaged Apple', 'To Clean Apple']\n","\n","for i in range(len(imgs)):\n","  plt.subplot(2, 2, i+1)\n","  plt.title(title[i])\n","  if i % 2 == 0:\n","    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n","  else:\n","    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pkf4rZRLsVG"},"source":["plt.figure(figsize=(8, 8))\n","\n","plt.subplot(121)\n","plt.title('Is a dammaged apple?')\n","plt.imshow(discriminator_y(sample_dammaged_apples)[0, ..., -1], cmap='RdBu_r')\n","\n","plt.subplot(122)\n","plt.title('Is a clean apple?')\n","plt.imshow(discriminator_x(sample_clean_apples)[0, ..., -1], cmap='RdBu_r')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pAf99MbaLDJK"},"source":["## Loss function and optimizer"]},{"cell_type":"code","metadata":{"id":"50bVCmSA1ukl"},"source":["LAMBDA = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hh-DCwIBCkQh"},"source":["loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qSEP1MB153E"},"source":["def discriminator_loss(real, generated):\n","  real_loss = loss_obj(tf.ones_like(real), real)\n","\n","  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n","\n","  total_disc_loss = real_loss + generated_loss\n","\n","  return total_disc_loss * 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7UkRhK617qE"},"source":["def generator_loss(generated):\n","  return loss_obj(tf.ones_like(generated), generated)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvLZc2mk2ATZ"},"source":["def calc_cycle_loss(real_image, cycled_image):\n","  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n","\n","  return LAMBDA * loss1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btDSE0ET2FRc"},"source":["def identity_loss(real_image, same_image):\n","  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n","  return LAMBDA * 0.5 * loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pmlxzyjk2HYx"},"source":["#Optimizer\n","generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2bhCQDdz2Kk3"},"source":["## DÃ©finition des checkpoints "]},{"cell_type":"code","metadata":{"id":"BEqkspZl2Mp9"},"source":["checkpoint_path = \"/checkpoints/ckps\"  #  checkpoints directory\n","\n","ckpt = tf.train.Checkpoint(generator_g=generator_g,\n","                           generator_f=generator_f,\n","                           discriminator_x=discriminator_x,\n","                           discriminator_y=discriminator_y,\n","                           generator_g_optimizer=generator_g_optimizer,\n","                           generator_f_optimizer=generator_f_optimizer,\n","                           discriminator_x_optimizer=discriminator_x_optimizer,\n","                           discriminator_y_optimizer=discriminator_y_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint already exists, restore the last checkpoint\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN5yjdtV2PzK"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"cyfHw-em2-gJ"},"source":["EPOCHS = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7jNMEVa2SfQ"},"source":["def generate_images(model, test_input,epoch=None):\n","  prediction = model(test_input)\n","\n","  plt.figure(figsize=(12, 12))\n","\n","  display_list = [test_input[0], prediction[0]]\n","  title = ['Input Image', 'Predicted Image']\n","\n","  for i in range(2):\n","    plt.title(title[i])\n","    # getting the pixel values between [0, 1] to plot it\n","    plt.imshow(display_list[i] * 0.5 + 0.5)\n","    plt.axis('off')\n","    if epoch != None :\n","      plt.savefig('/Training_images/image_{:04d}.png'.format(epoch)) # save training images\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ru2WrftP2ZfT"},"source":["# training function\n","@tf.function\n","def train_step(real_x, real_y):\n","\n","  with tf.GradientTape(persistent=True) as tape:\n","    # Generator G translates X -> Y\n","    # Generator F translates Y -> X.\n","\n","    fake_y = generator_g(real_x, training=True)\n","    cycled_x = generator_f(fake_y, training=True)\n","\n","    fake_x = generator_f(real_y, training=True)\n","    cycled_y = generator_g(fake_x, training=True)\n","\n","    # same_x and same_y are used for identity loss\n","    same_x = generator_f(real_x, training=True)\n","    same_y = generator_g(real_y, training=True)\n","\n","    disc_real_x = discriminator_x(real_x, training=True)\n","    disc_real_y = discriminator_y(real_y, training=True)\n","\n","    disc_fake_x = discriminator_x(fake_x, training=True)\n","    disc_fake_y = discriminator_y(fake_y, training=True)\n","\n","    #  Calculate the loss\n","    gen_g_loss = generator_loss(disc_fake_y)\n","    gen_f_loss = generator_loss(disc_fake_x)\n","\n","    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n","\n","    # Total generator loss = adversarial loss + cycle loss\n","    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n","    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n","\n","    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n","    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n","\n","  # Calculate the gradients for generator and discriminator\n","  generator_g_gradients = tape.gradient(total_gen_g_loss, \n","                                        generator_g.trainable_variables)\n","  generator_f_gradients = tape.gradient(total_gen_f_loss, \n","                                        generator_f.trainable_variables)\n","\n","  discriminator_x_gradients = tape.gradient(disc_x_loss, \n","                                            discriminator_x.trainable_variables)\n","  discriminator_y_gradients = tape.gradient(disc_y_loss, \n","                                            discriminator_y.trainable_variables)\n","\n","  # Apply the gradients to the optimizer\n","  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n","                                            generator_g.trainable_variables))\n","\n","  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n","                                            generator_f.trainable_variables))\n","\n","  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n","                                                discriminator_x.trainable_variables))\n","\n","  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n","                                                discriminator_y.trainable_variables))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PmHE4ep2d3u"},"source":["# training\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  n = 0\n","  for image_x, image_y in tf.data.Dataset.zip((train_clean_apples, train_dammaged_apples)):\n","    train_step(image_x, image_y)\n","    if n % 10 == 0:\n","      print ('.', end='')\n","    n += 1\n","\n","  clear_output(wait=True)\n","  generate_images(generator_g, sample_clean_apples, epoch+240)\n","\n","  if (epoch + 1) % 5 == 0:\n","    tf.saved_model.save(obj, export_dir, signatures=None, options=None)\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path)) \n","\n","  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"],"execution_count":null,"outputs":[]}]}